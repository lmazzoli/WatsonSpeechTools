{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the necessary libraries\n",
    "import sys\n",
    "import os\n",
    "from os.path import join, dirname\n",
    "import json\n",
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_watson.speech_to_text_v1 import CustomWord\n",
    "from ibm_cloud_sdk_core.authenticators import BearerTokenAuthenticator\n",
    "from ibm_watson.websocket import RecognizeCallback, AudioSource\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the CP4D Speech to Text Service\n",
    "bearer = \"XXX\"\n",
    "authenticator = BearerTokenAuthenticator(bearer)\n",
    "\n",
    "speech_to_text = SpeechToTextV1(\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "speech_to_text.set_service_url('https://cp4d-cpd-cp4d.icp-poc.am.lilly.com/speech-to-text/watson-speech-base/instances/1608759635733/api')\n",
    "speech_to_text.set_disable_ssl_verification(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve the Speech to Text models\n",
    "speech_models = speech_to_text.list_models().get_result()\n",
    "print(json.dumps(speech_models, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the audio file name that should be transcribed\n",
    "fileName = \"1030237_FVSSS_June15th2020.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the MyRecognizeCallback class\n",
    "class MyRecognizeCallback(RecognizeCallback):\n",
    "    def __init__(self):\n",
    "        RecognizeCallback.__init__(self)\n",
    "\n",
    "    def on_transcription(self, transcript):\n",
    "        print(transcript)\n",
    "\n",
    "    def on_connected(self):\n",
    "        print('Connection was successful')\n",
    "\n",
    "    def on_error(self, error):\n",
    "        print('Error received: {}'.format(error))\n",
    "\n",
    "    def on_inactivity_timeout(self, error):\n",
    "        print('Inactivity timeout: {}'.format(error))\n",
    "\n",
    "    def on_listening(self):\n",
    "        print('Service is listening')\n",
    "\n",
    "    def on_hypothesis(self, hypothesis):\n",
    "        print(hypothesis)\n",
    "\n",
    "    def on_data(self, data):\n",
    "        #print(data)\n",
    "        f_data = open(fileName[:-4] + \"_transcript.json\", \"w\")\n",
    "        f_data.write(json.dumps(data))\n",
    "        f_data.close()\n",
    "\n",
    "        \n",
    "mycallback = MyRecognizeCallback()\n",
    "audio_file = open(fileName, 'rb')\n",
    "audio_source = AudioSource(audio_file)\n",
    "\n",
    "#Start the transcription request\n",
    "t = speech_to_text.recognize_using_websocket (audio=audio_source, content_type=\"audio/mp3\", recognize_callback=mycallback, speaker_labels=True, smart_formatting=True, model=\"en-US_ShortForm_NarrowbandModel\", inactivity_timeout=600)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Open Transcript File\n",
    "with open(fileName [:-4] + \"_transcript.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Retrieve Speaker Labels section of the JSON\n",
    "speaker_labels = data[\"speaker_labels\"]\n",
    "\n",
    "#set counter\n",
    "i = 0\n",
    "last_speaker = 0\n",
    "phrase = \"\"\n",
    "\n",
    "#Full transcript file name\n",
    "f1_data = open(fileName [:-4] + \"_transcript.txt\" , \"w\")\n",
    "\n",
    "#Iterate through transcript results section of the JSON file (speaker labels are available)\n",
    "for result in data[\"results\"]:\n",
    "    for timestamp in result[\"alternatives\"][0][\"timestamps\"]:\n",
    "        #Retrieve each transcribed word and align it to the speaker \n",
    "        current_speaker = speaker_labels [i][\"speaker\"]\n",
    "        current_phrase =timestamp [0].replace(\"%HESITATION\",\"\")\n",
    "        #If Speaker has not changed, compound the speech phrase\n",
    "        if (current_speaker==last_speaker):\n",
    "            phrase = phrase + \" \" + current_phrase\n",
    "        #print the last speaker phrase and start the new speaker phrase\n",
    "        else:\n",
    "            #print (\"Speaker: \" +  str(last_speaker) + \" \" + phrase)\n",
    "            f_data = open(fileName [:-4] + \"_\" + str(i) + \".json\" , \"w\")\n",
    "            data_out = {'speaker': last_speaker, 'text': phrase}\n",
    "            f_data.write(json.dumps(data_out, indent=4))\n",
    "            f_data.close()\n",
    "            f1_data.write(\"Speaker: \" +  str(last_speaker) + \" \" + phrase + \"\\n\")\n",
    "            phrase = current_phrase\n",
    "            last_speaker = current_speaker\n",
    "        i = i + 1\n",
    "        #print (i)\n",
    "\n",
    "#print (\"Speaker:\" +  str(last_speaker) + \" \" + phrase)\n",
    "f_data = open(fileName [:-4] + \"_\" + str(i) + \".json\" , \"w\")\n",
    "data_out = {'speaker': last_speaker, 'text': phrase}\n",
    "f_data.write(json.dumps(data_out, indent=4))\n",
    "f_data.close()\n",
    "\n",
    "f1_data.write(\"Speaker: \" +  str(last_speaker) + \" \" + phrase+ \"\\n\")\n",
    "f1_data.close()\n",
    "#print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the transcript phrases (speaker labels are not available)\n",
    "for result in data[\"results\"]:\n",
    "    print (result[\"alternatives\"][0][\"transcript\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list custom language models\n",
    "language_models = speech_to_text.list_language_models().get_result()\n",
    "print(json.dumps(language_models, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom language model\n",
    "language_model = speech_to_text.create_language_model(\n",
    "    'Eli Lilly Custom Language Model',\n",
    "    'en-US_NarrowbandModel',\n",
    "    description='Eli Lilly Custom Language Model')\n",
    "\n",
    "print(json.dumps(language_model.get_result(), indent=2))\n",
    "\n",
    "# Store the customize id returned from the STT service\n",
    "customization_id = language_model.get_result()['customization_id']\n",
    "\n",
    "print(customization_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model id (save for future reuse)\n",
    "#V1\n",
    "#customization_id = '34723c52-19b0-4e25-b2cc-74262b65a2e4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Custom Language model\n",
    "speech_model = speech_to_text.get_language_model(customization_id)\n",
    "\n",
    "print(json.dumps(speech_model.get_result(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list custom language models\n",
    "language_models = speech_to_text.list_language_models().get_result()\n",
    "print(json.dumps(language_models, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete a custom language model\n",
    "#speech_to_text.delete_language_model(\"XXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Corpora\n",
    "corpora = speech_to_text.list_corpora(customization_id).get_result()\n",
    "print(json.dumps(corpora, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a corpus\n",
    "corpus_name = \"LM_English v1\"\n",
    "headers = {'Content-Type' : \"multipart/form-data\"}\n",
    "\n",
    "with open('corpus.txt','rb') as corpus_file:\n",
    "    #add the corpus\n",
    "    speech_to_text.add_corpus(customization_id = customization_id, headers=headers, corpus_name = corpus_name, corpus_file = corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Corpora\n",
    "corpora = speech_to_text.list_corpora(customization_id).get_result()\n",
    "print(json.dumps(corpora, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List custom words\n",
    "words = speech_to_text.list_words(customization_id).get_result()\n",
    "print(json.dumps(words, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Custom words\n",
    "custom_word_list = []\n",
    "custom_word_list.append (CustomWord(word='NAME', sounds_like=['VAR', 'BAR'], display_as='NAME'))\n",
    "custom_word_list.append (CustomWord(word='NAMEA', sounds_like=['VARA', 'BARA'], display_as='NAMEA'))\n",
    "speech_to_text.add_words(customization_id,custom_word_list).get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List custom words\n",
    "words = speech_to_text.list_words(customization_id).get_result()\n",
    "print(json.dumps(words, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a custom word\n",
    "speech_to_text.delete_word(customization_id, 'NAME').get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue a train request\n",
    "print(speech_to_text.train_language_model(customization_id).get_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list custom language models - ensure the status is 'available'\n",
    "language_models = speech_to_text.list_language_models().get_result()\n",
    "print(json.dumps(language_models, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a corpus\n",
    "speech_to_text.delete_corpus(customization_id, corpus_name).get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete a custom language model\n",
    "speech_to_text.delete_language_model(customization_id).get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list custom language models\n",
    "\n",
    "language_models = speech_to_text.list_language_models().get_result()\n",
    "print(json.dumps(language_models, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
